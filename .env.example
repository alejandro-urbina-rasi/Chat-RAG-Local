# ===========================================
# CONFIGURACIÓN RAG LOCAL - AGENTE (EJEMPLO)
# ===========================================
# Copia este archivo a .env y ajusta los valores según tu entorno

# ============= SERVIDOR =============
# Puerto donde corre el servidor
PORT=3000

# Entorno: development, production, test
NODE_ENV=development

# ============= OLLAMA =============
# URL base de Ollama (cambiar si corre en otro host)
OLLAMA_BASE_URL=http://localhost:11434

# Modelo para generar embeddings
# Opciones: nomic-embed-text (274MB), mxbai-embed-large (670MB), all-minilm
# Recomendado: nomic-embed-text para hardware limitado
OLLAMA_EMBED_MODEL=nomic-embed-text

# Modelo LLM para generación de respuestas
# Opciones: mistral, llama2, codellama, phi, gemma
OLLAMA_LLM_MODEL=mistral

# Timeout para requests a Ollama (en milisegundos)
# 200000 = 3.3 minutos (recomendado para hardware limitado)
# Reducir a 120000 (2 min) si tienes hardware potente
OLLAMA_TIMEOUT=200000

# Temperatura del LLM (0.0-2.0)
# Controla la aleatoriedad de las respuestas
# 0.1 = Muy determinista, evita alucinaciones (RECOMENDADO para RAG)
# 0.8 = Por defecto de Mistral (más creativo, puede alucinar)
# 1.0+ = Muy creativo (NO recomendado para RAG)
OLLAMA_TEMPERATURE=0.1

# Top P - Nucleus sampling (0.0-1.0)
# Considera solo tokens cuya probabilidad acumulada alcanza este valor
# 0.9 = Considera top 90% de probabilidades (recomendado)
# 1.0 = Considera todas las opciones
OLLAMA_TOP_P=0.9

# Top K - Limita el vocabulario
# Solo considera los K tokens más probables
# 40 = Evita tokens poco probables, reduce alucinaciones (recomendado)
# 0 = Sin límite (no recomendado para RAG)
OLLAMA_TOP_K=40

# ============= RAG =============
# Tamaño máximo de chunks en caracteres
# 800 = Óptimo para evitar cortes en nombres completos ("RASI SOLUCIONES S.A.S." vs "S.")
# 600 = Balance entre calidad y velocidad de respuesta
# 500 = Más rápido pero puede cortar contexto importante
RAG_CHUNK_SIZE=800

# Número de oraciones a repetir entre chunks (overlap semántico)
# 2 = Recomendado para mantener contexto sin redundancia excesiva
# 1 = Mínimo overlap (más rápido, menor calidad)
# 3 = Más contexto pero genera duplicados
RAG_CHUNK_OVERLAP=2

# Top-K: Número de documentos más relevantes a recuperar
# 3 = Óptimo para hardware limitado (evita timeouts)
# 5 = Mejor recall pero puede causar timeouts en hardware limitado
# Advertencia: Valores >3 pueden exceder timeout con CHUNK_SIZE=800
RAG_TOP_K=3

# Umbral de similitud mínima (0-1)
# 0.0 = acepta todo, 1.0 = solo perfectamente similar
# 0.2 = Permisivo, captura más resultados relevantes con nomic-embed-text
# 0.3 = Más estricto (usar con modelos de embeddings más potentes)
RAG_SIMILARITY_THRESHOLD=0.2

# Modo estricto por defecto
# true = solo responde con info de documentos (recomendado)
# false = puede usar conocimiento general del LLM
RAG_STRICT_MODE=true

# ============= RUTAS =============
# Directorio donde se guardan PDFs subidos
UPLOADS_DIR=./uploads

# Directorio donde se guarda la base de datos
DATA_DIR=./data

# ============= AUTENTICACIÓN =============
# Contraseña del usuario admin por defecto
# IMPORTANTE: Cambia esto después de la primera instalación
ADMIN_PASSWORD=admin123

# ============= SEGURIDAD =============
# Rate limiting: máximo de requests por ventana de tiempo
RATE_LIMIT_MAX=100

# Ventana de tiempo para rate limit (en milisegundos)
# 60000 = 1 minuto
RATE_LIMIT_WINDOW_MS=60000

# CORS: Orígenes permitidos (separados por coma)
# * = permitir todos (NO recomendado en producción)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# ============= LOGGING =============
# Nivel de logging: debug, info, warn, error
LOG_LEVEL=info

# ===========================================
# NOTAS IMPORTANTES:
# ===========================================
#
# 1. OLLAMA:
#    - Asegúrate de que Ollama esté corriendo antes de iniciar el servidor
#    - Verifica que los modelos estén descargados:
#      ollama pull nomic-embed-text
#      ollama pull mistral
#
# 2. RAG_CHUNK_SIZE:
#    - Muy pequeño (<500): Fragmenta demasiado el contexto, corta nombres
#    - Óptimo (800): Evita cortar nombres completos, mejor contexto
#    - Muy grande (>1000): Puede causar latencia alta antes de streaming
#
# 3. RAG_SIMILARITY_THRESHOLD:
#    - Muy bajo (<0.15): Incluye chunks irrelevantes
#    - Óptimo (0.2): Balance entre precisión y recall con nomic-embed-text
#    - Muy alto (>0.3): Puede no encontrar nada relevante
#
# 4. HARDWARE LIMITADO:
#    - Mantén RAG_TOP_K=3 para evitar timeouts
#    - Usa OLLAMA_TIMEOUT=200000 (3.3 min) para dar margen al LLM
#    - Si aún hay timeouts, reduce RAG_CHUNK_SIZE a 600
#
# 5. DUPLICADOS EN BASE DE DATOS:
#    - Si encuentras duplicados, ejecuta:
#      sqlite3 data/vectors.db "DELETE FROM documents WHERE id NOT IN (SELECT MIN(id) FROM documents GROUP BY text)"
#      sqlite3 data/vectors.db "VACUUM"
#
# 6. PRODUCCIÓN:
#    - Cambia NODE_ENV=production
#    - Cambia ADMIN_PASSWORD a algo seguro
#    - Configura CORS_ORIGINS con dominios específicos
#    - Ajusta RATE_LIMIT_MAX según carga esperada
#    - Considera aumentar hardware para TOP_K=5 y mejor recall
